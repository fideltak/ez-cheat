{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ec1aa6-b992-47f0-87fe-379447a64642",
   "metadata": {},
   "source": [
    "# Nvidia Inference Microservice(NIM) for Llama3 SQLcoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9127f-2f8b-484e-9424-4c08467eeb21",
   "metadata": {},
   "source": [
    "## Create Text2SQL client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4d60c6-ae3d-469d-919a-2920ec9b5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# your NIM address\n",
    "nim_base_url = \"http://llama3-sqlcoder8b.test.svc.cluster.local/v1\"\n",
    "\n",
    "client = OpenAI(base_url=nim_base_url, api_key=\"not-used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53141ac-a537-496f-b5c1-63a77cd1792e",
   "metadata": {},
   "source": [
    "### Set text2SQL model name for client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df160ea5-7791-4050-8f95-fa7b94188339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defog/llama-3-sqlcoder-8b\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "req = urllib.request.Request(f\"{nim_base_url}/models\")\n",
    "with urllib.request.urlopen(req) as res:\n",
    "    body = res.read().decode('utf-8')\n",
    "    body_obj = json.loads(body)\n",
    "\n",
    "for item in body_obj['data']:\n",
    "    print(item['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0f2b1b-0580-446a-8fc5-d9789993ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see some models above section, choose text2sql model.\n",
    "model_name = 'defog/llama-3-sqlcoder-8b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b8800-c840-4494-a6d4-87e0426301c0",
   "metadata": {},
   "source": [
    "## Prompt Engineering\n",
    "I used langchain sql_database prompt as a reference.\n",
    "- [langchain](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/sql_database/prompt.py#L190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db7731a-3d2a-45e0-9002-2c26402628e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"postgresql://admin:password@dvd-postgresql-r.test.svc.cluster.local/dvdrental\")\n",
    "table_info = db.get_table_info(db.get_usable_table_names())\n",
    "\n",
    "PROMPT_SUFFIX = f\"\"\"\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "There are 15 tables in the dvdrental database:\n",
    "actor – stores actor data including first name and last name.\n",
    "film – stores film data such as title, release year, length, rating, etc.\n",
    "film_actor – stores the relationships between films and actors.\n",
    "category – stores film’s categories data.\n",
    "film_category- stores the relationships between films and categories.\n",
    "store – contains the store data including manager staff and address.\n",
    "inventory – stores inventory data.\n",
    "rental – stores rental data.\n",
    "payment – stores customer’s payments.\n",
    "staff – stores staff data.\n",
    "customer – stores customer data.\n",
    "address – stores address data for staff and customers\n",
    "city – stores city names.\n",
    "country – stores country names.\n",
    "\"\"\"\n",
    "\n",
    "_postgres_prompt = \"\"\"\n",
    "You are a PostgreSQL version 16 expert. Given an input question, first create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per PostgreSQL. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use CURRENT_DATE function to get the current date, if the question involves \"today\".\n",
    "\n",
    "You must response SQL query only.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc577755-209b-4ec6-8589-5b16e02a264b",
   "metadata": {},
   "source": [
    "## Query to Text2SQL and Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29b24f15-7b75-42ef-96a2-6cd653d3e202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "[Question]\n",
      " Popular dvd titles top5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Generated query from defog/llama-3-sqlcoder-8b]\n",
      " SELECT f.title, COUNT(r.rental_id) AS total_rentals FROM film f JOIN film_category fc ON f.film_id = fc.film_id JOIN category c ON fc.category_id = c.category_id JOIN inventory i ON f.film_id = i.film_id JOIN rental r ON i.inventory_id = r.inventory_id GROUP BY f.title ORDER BY total_rentals DESC LIMIT 5;\n",
      "\n",
      "[Query Result]\n",
      " [{'title': 'Bucket Brotherhood', 'total_rentals': 34}, {'title': 'Rocketeer Mother', 'total_rentals': 33}, {'title': 'Grit Clockwork', 'total_rentals': 32}, {'title': 'Forward Temple', 'total_rentals': 32}, {'title': 'Juggler Hardly', 'total_rentals': 32}]\n",
      "\n",
      "\n",
      "[Answer from defog/llama-3-sqlcoder-8b]\n",
      "Based on the data, the top 5 most popular DVD titles are:\n",
      "\n",
      "1. Bucket Brotherhood (34 rentals)\n",
      "2. Rocketeer Mother (33 rentals)\n",
      "3. Grit Clockwork (32 rentals)\n",
      "4. Forward Temple (32 rentals)\n",
      "5. Juggler Hardly (32 rentals)\n",
      "\n",
      "These titles have had the most rentals, according to the data provided.\n"
     ]
    }
   ],
   "source": [
    "question = input(\"[Question]\\n\")\n",
    "print('')\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": _postgres_prompt + PROMPT_SUFFIX\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question\n",
    "    }\n",
    "]\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "db_query = assistant_message.content\n",
    "\n",
    "print(f\"[Generated query from {model_name}]\\n {db_query}\\n\")\n",
    "\n",
    "# Access to postgres\n",
    "import psycopg2\n",
    "postgresql_address = 'dvd-postgresql-r.test.svc.cluster.local'\n",
    "postgresql_user = 'admin'\n",
    "postgresql_password = 'password'\n",
    "postgresql_database = 'dvdrental'\n",
    "connection = psycopg2.connect(f\"host={postgresql_address} dbname={postgresql_database} user={postgresql_user} password={postgresql_password}\")\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(db_query)\n",
    "columns = [desc[0] for desc in cursor.description]\n",
    "rows = cursor.fetchall()\n",
    "res = []\n",
    "for row in rows:\n",
    "    row_data = dict(zip(columns, row))\n",
    "    res.append(row_data)\n",
    "\n",
    "print(f\"[Query Result]\\n {res}\\n\")\n",
    "\n",
    "answer_msg = f\"\"\"\n",
    "A user asked me that {question}.\n",
    "To answer this question, I did query to the database and got below data.\n",
    "{str(res)}\n",
    "Please answer it in place of me.\n",
    "\"\"\"\n",
    "\n",
    "answer_response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": answer_msg}\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "print(f\"\\n[Answer from {model_name}]\")\n",
    "print(answer_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b58e5-6c7b-4b14-92f7-a5df1b5adafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
